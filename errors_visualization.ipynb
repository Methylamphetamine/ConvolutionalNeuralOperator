{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 13:43:10.495083: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-04 13:43:11.174453: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home1/w/wangh19/mpi/mpich-4.1.2/install/lib:/usr/local/cuda-12.1/extras/CUPTI/lib64::/usr/local/cuda-12.1/targets/x86_64-linux/lib::/usr/local/cuda-12.1/lib64::/home1/w/wangh19/mpi/mpich-4.1.2/install/lib:/usr/local/cuda-12.1/extras/CUPTI/lib64::/usr/local/cuda-12.1/targets/x86_64-linux/lib::/usr/local/cuda-12.1/lib64:\n",
      "2023-12-04 13:43:11.174648: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home1/w/wangh19/mpi/mpich-4.1.2/install/lib:/usr/local/cuda-12.1/extras/CUPTI/lib64::/usr/local/cuda-12.1/targets/x86_64-linux/lib::/usr/local/cuda-12.1/lib64::/home1/w/wangh19/mpi/mpich-4.1.2/install/lib:/usr/local/cuda-12.1/extras/CUPTI/lib64::/usr/local/cuda-12.1/targets/x86_64-linux/lib::/usr/local/cuda-12.1/lib64:\n",
      "2023-12-04 13:43:11.174656: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "# NOTE changed normalization\n",
    "from Problems.CNOBenchmarks_new_normalization import Darcy, Airfoil, DiscContTranslation, ContTranslation, AllenCahn, SinFrequency, WaveEquation, ShearLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of model parameters: 748841 (~2.86MiB)\n"
     ]
    }
   ],
   "source": [
    "training_properties = {\n",
    "    \"learning_rate\": 0.001, # CHECKED\n",
    "    \"scheduler_step\": 10,\n",
    "    \"scheduler_gamma\": 0.98, # CHECKED\n",
    "    \"epochs\": 1000,\n",
    "    \"batch_size\": 32,\n",
    "    \"exp\": 1,                # Do we use L1 or L2 errors? Default: L1\n",
    "    \"training_samples\": 256  # How many training samples?\n",
    "}\n",
    "model_architecture_ = {\n",
    "    \n",
    "    #Parameters to be chosen with model selection:\n",
    "    # \"N_layers\": 3,            # Number of (D) & (U) blocks CHANGE M\n",
    "    # \"channel_multiplier\": 32, # Parameter d_e (how the number of channels changes) CHANGE\n",
    "    # \"N_res\": 4,               # Number of (R) blocks in the middle networs. CHANGE\n",
    "    # \"N_res_neck\" : 6,         # Number of (R) blocks in the BN CHANGE, r\n",
    "    \n",
    "    #Other parameters:\n",
    "    \"in_size\": 64,            # Resolution of the computational grid\n",
    "    \"retrain\": 4,             # Random seed\n",
    "    \"kernel_size\": 3,         # Kernel size. CHECKED\n",
    "    \"FourierF\": 0,            # Number of Fourier Features in the input channels. Default is 0.\n",
    "    \"activation\": 'cno_lrelu',# cno_lrelu or lrelu\n",
    "    \n",
    "    #Filter properties:\n",
    "    \"cutoff_den\": 2.0001,     # Cutoff parameter.\n",
    "    \"lrelu_upsampling\": 2,    # Coefficient N_{\\sigma}. Default is 2.\n",
    "    \"half_width_mult\": 0.8,   # Coefficient c_h. Default is 1 CHECKED\n",
    "    \"filter_size\": 6,         # 2xfilter_size is the number of taps N_{tap}. Default is 6. CHECKED\n",
    "    \"radial_filter\": 0,       # Is the filter radially symmetric? Default is 0 - NO.\n",
    "}\n",
    "\n",
    "#   \"which_example\" can be \n",
    "\n",
    "#   poisson             : Poisson equation \n",
    "#   wave_0_5            : Wave equation\n",
    "#   cont_tran           : Smooth Transport\n",
    "#   disc_tran           : Discontinuous Transport\n",
    "#   allen               : Allen-Cahn equation\n",
    "#   shear_layer         : Navier-Stokes equations\n",
    "#   airfoil             : Compressible Euler equations\n",
    "#   darcy               : Darcy Flow\n",
    "\n",
    "which_example = 'poisson'\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# NOTE moved most of the hyperparameter variables to after the individual example setup\n",
    "batch_size = training_properties[\"batch_size\"]\n",
    "\n",
    "\n",
    "# NOTE add ood example, set correct training sample size\n",
    "if which_example == \"shear_layer\":\n",
    "    training_properties.update({\n",
    "        \"weight_decay\": 1e-10, # CHANGE\n",
    "    })\n",
    "    model_architecture_.update({\n",
    "        #Parameters to be chosen with model selection:\n",
    "        \"N_layers\": 3,            # Number of (D) & (U) blocks CHANGE M\n",
    "        \"channel_multiplier\": 32, # Parameter d_e (how the number of channels changes) CHANGE\n",
    "        \"N_res\": 1,               # Number of (R) blocks in the middle networs. CHANGE\n",
    "        \"N_res_neck\" : 8,         # Number of (R) blocks in the BN CHANGE, r\n",
    "    })\n",
    "    training_samples = training_properties[\"training_samples\"] = 750\n",
    "    example = ShearLayer(model_architecture_, device, batch_size, training_samples, size = 64)\n",
    "    ood_example = ShearLayer(model_architecture_, device, batch_size, training_samples, size = 64, in_dist=False)\n",
    "elif which_example == \"poisson\":\n",
    "    training_properties.update({\n",
    "        \"weight_decay\": 1e-6, # CHANGE\n",
    "    })\n",
    "    model_architecture_.update({\n",
    "        #Parameters to be chosen with model selection:\n",
    "        \"N_layers\": 3,            # Number of (D) & (U) blocks CHANGE M\n",
    "        \"channel_multiplier\": 16, # Parameter d_e (how the number of channels changes) CHANGE\n",
    "        \"N_res\": 4,               # Number of (R) blocks in the middle networs. CHANGE\n",
    "        \"N_res_neck\" : 6,         # Number of (R) blocks in the BN CHANGE, r\n",
    "    })\n",
    "    training_samples = training_properties[\"training_samples\"] = 1024\n",
    "    example = SinFrequency(model_architecture_, device, batch_size, training_samples)\n",
    "    ood_example = SinFrequency(model_architecture_, device, batch_size, training_samples, in_dist=False)\n",
    "elif which_example == \"wave_0_5\":\n",
    "    training_properties.update({\n",
    "        \"weight_decay\": 1e-10, # CHANGE\n",
    "    })\n",
    "    model_architecture_.update({\n",
    "        #Parameters to be chosen with model selection:\n",
    "        \"N_layers\": 3,            # Number of (D) & (U) blocks CHANGE M\n",
    "        \"channel_multiplier\": 48, # Parameter d_e (how the number of channels changes) CHANGE\n",
    "        \"N_res\": 4,               # Number of (R) blocks in the middle networs. CHANGE\n",
    "        \"N_res_neck\" : 6,         # Number of (R) blocks in the BN CHANGE, r\n",
    "    })\n",
    "    training_samples = training_properties[\"training_samples\"] = 512\n",
    "    example = WaveEquation(model_architecture_, device, batch_size, training_samples)\n",
    "    ood_example = WaveEquation(model_architecture_, device, batch_size, training_samples, in_dist=False)\n",
    "elif which_example == \"allen\":\n",
    "    training_properties.update({\n",
    "        \"weight_decay\": 1e-6, # CHANGE\n",
    "    })\n",
    "    model_architecture_.update({\n",
    "        #Parameters to be chosen with model selection:\n",
    "        \"N_layers\": 3,            # Number of (D) & (U) blocks CHANGE M\n",
    "        \"channel_multiplier\": 48, # Parameter d_e (how the number of channels changes) CHANGE\n",
    "        \"N_res\": 4,               # Number of (R) blocks in the middle networs. CHANGE\n",
    "        \"N_res_neck\" : 8,         # Number of (R) blocks in the BN CHANGE, r\n",
    "    })\n",
    "    training_samples = training_properties[\"training_samples\"] = 256\n",
    "    example = AllenCahn(model_architecture_, device, batch_size, training_samples)\n",
    "    ood_example = AllenCahn(model_architecture_, device, batch_size, training_samples, in_dist=False)\n",
    "elif which_example == \"cont_tran\":\n",
    "    training_properties.update({\n",
    "        \"weight_decay\": 1e-6, # CHANGE\n",
    "    })\n",
    "    model_architecture_.update({\n",
    "        #Parameters to be chosen with model selection:\n",
    "        \"N_layers\": 3,            # Number of (D) & (U) blocks CHANGE M\n",
    "        \"channel_multiplier\": 32, # Parameter d_e (how the number of channels changes) CHANGE\n",
    "        \"N_res\": 2,               # Number of (R) blocks in the middle networs. CHANGE\n",
    "        \"N_res_neck\" : 6,         # Number of (R) blocks in the BN CHANGE, r\n",
    "    })\n",
    "    training_samples = training_properties[\"training_samples\"] = 512\n",
    "    example = ContTranslation(model_architecture_, device, batch_size, training_samples)\n",
    "    ood_example = ContTranslation(model_architecture_, device, batch_size, training_samples, in_dist=False)\n",
    "elif which_example == \"disc_tran\":\n",
    "    training_properties.update({\n",
    "        \"weight_decay\": 1e-6, # CHANGE\n",
    "    })\n",
    "    model_architecture_.update({\n",
    "        #Parameters to be chosen with model selection:\n",
    "        \"N_layers\": 3,            # Number of (D) & (U) blocks CHANGE M\n",
    "        \"channel_multiplier\": 32, # Parameter d_e (how the number of channels changes) CHANGE\n",
    "        \"N_res\": 5,               # Number of (R) blocks in the middle networs. CHANGE\n",
    "        \"N_res_neck\" : 4,         # Number of (R) blocks in the BN CHANGE, r\n",
    "    })\n",
    "    training_samples = training_properties[\"training_samples\"] = 512\n",
    "    example = DiscContTranslation(model_architecture_, device, batch_size, training_samples)\n",
    "    ood_example = DiscContTranslation(model_architecture_, device, batch_size, training_samples, in_dist=False)\n",
    "elif which_example == \"airfoil\":\n",
    "    training_properties.update({\n",
    "        \"weight_decay\": 1e-10, # CHANGE\n",
    "    })\n",
    "    model_architecture_.update({\n",
    "        #Parameters to be chosen with model selection:\n",
    "        \"N_layers\": 4,            # Number of (D) & (U) blocks CHANGE M\n",
    "        \"channel_multiplier\": 48, # Parameter d_e (how the number of channels changes) CHANGE\n",
    "        \"N_res\": 1,               # Number of (R) blocks in the middle networs. CHANGE\n",
    "        \"N_res_neck\" : 8,         # Number of (R) blocks in the BN CHANGE, r\n",
    "    })\n",
    "    training_samples = training_properties[\"training_samples\"] = 750\n",
    "    model_architecture_[\"in_size\"] = 128\n",
    "    example = Airfoil(model_architecture_, device, batch_size, training_samples)\n",
    "    ood_example = Airfoil(model_architecture_, device, batch_size, training_samples, in_dist=False)\n",
    "elif which_example == \"darcy\":\n",
    "    training_properties.update({\n",
    "        \"weight_decay\": 1e-6, # CHANGE\n",
    "    })\n",
    "    model_architecture_.update({\n",
    "        #Parameters to be chosen with model selection:\n",
    "        \"N_layers\": 3,            # Number of (D) & (U) blocks CHANGE M\n",
    "        \"channel_multiplier\": 48, # Parameter d_e (how the number of channels changes) CHANGE\n",
    "        \"N_res\": 4,               # Number of (R) blocks in the middle networs. CHANGE\n",
    "        \"N_res_neck\" : 4,         # Number of (R) blocks in the BN CHANGE, r\n",
    "    })\n",
    "    training_samples = training_properties[\"training_samples\"] = 256\n",
    "    example = Darcy(model_architecture_, device, batch_size, training_samples)\n",
    "    ood_example = Darcy(model_architecture_, device, batch_size, training_samples, in_dist=False)\n",
    "else:\n",
    "    raise ValueError()\n",
    "\n",
    "    \n",
    "#-----------------------------------Train--------------------------------------\n",
    "model = example.model\n",
    "n_params = model.print_size()\n",
    "train_loader = example.train_loader #TRAIN LOADER\n",
    "val_loader = example.val_loader #VALIDATION LOADER\n",
    "# NOTE add ood loader\n",
    "test_loader = example.test_loader\n",
    "ood_test_loader = ood_example.test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('eth/eth_poisson_model.pkl', map_location=torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
      "0.2109133005142212\n",
      "0.2718319892883301\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    final_test_relative_l2 = []\n",
    "    \n",
    "    for step, (input_batch, output_batch) in enumerate(test_loader):\n",
    "        \n",
    "        input_batch = input_batch.to(device)\n",
    "        output_batch = output_batch.to(device)\n",
    "        output_pred_batch = model(input_batch)\n",
    "        \n",
    "        if which_example == \"airfoil\": #Mask the airfoil shape\n",
    "            output_pred_batch[input_batch==1] = 1\n",
    "            output_batch[input_batch==1] = 1\n",
    "        \n",
    "        loss_f = torch.mean(abs(output_pred_batch - output_batch), axis = [1,2,3]) / torch.mean(abs(output_batch), axis = [1,2,3]) * 100\n",
    "        final_test_relative_l2.append(loss_f.detach().cpu().numpy())\n",
    "    final_test_relative_l2 = np.concatenate(final_test_relative_l2, 0)\n",
    "\n",
    "    ood_test_relative_l2 = []\n",
    "    \n",
    "    for step, (input_batch, output_batch) in enumerate(ood_test_loader):\n",
    "        \n",
    "        input_batch = input_batch.to(device)\n",
    "        output_batch = output_batch.to(device)\n",
    "        output_pred_batch = model(input_batch)\n",
    "        \n",
    "        if which_example == \"airfoil\": #Mask the airfoil shape\n",
    "            output_pred_batch[input_batch==1] = 1\n",
    "            output_batch[input_batch==1] = 1\n",
    "        \n",
    "        loss_f = torch.mean(abs(output_pred_batch - output_batch), axis = [1,2,3]) / torch.mean(abs(output_batch), axis = [1,2,3]) * 100\n",
    "        ood_test_relative_l2.append(loss_f.detach().cpu().numpy())\n",
    "    ood_test_relative_l2 = np.concatenate(ood_test_relative_l2, 0)\n",
    "\n",
    "print(np.median(final_test_relative_l2).item())\n",
    "print(np.median(ood_test_relative_l2).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('TrainedReportedModels_NoEarlyStopping_new_normalization/CNO_poisson_1/model.pkl', map_location=torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2851915657520294\n",
      "0.43258821964263916\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    final_test_relative_l2 = []\n",
    "    \n",
    "    for step, (input_batch, output_batch) in enumerate(test_loader):\n",
    "        \n",
    "        input_batch = input_batch.to(device)\n",
    "        output_batch = output_batch.to(device)\n",
    "        output_pred_batch = model(input_batch)\n",
    "        \n",
    "        if which_example == \"airfoil\": #Mask the airfoil shape\n",
    "            output_pred_batch[input_batch==1] = 1\n",
    "            output_batch[input_batch==1] = 1\n",
    "        \n",
    "        loss_f = torch.mean(abs(output_pred_batch - output_batch), axis = [1,2,3]) / torch.mean(abs(output_batch), axis = [1,2,3]) * 100\n",
    "        final_test_relative_l2.append(loss_f.detach().cpu().numpy())\n",
    "    final_test_relative_l2 = np.concatenate(final_test_relative_l2, 0)\n",
    "\n",
    "    ood_test_relative_l2 = []\n",
    "    \n",
    "    for step, (input_batch, output_batch) in enumerate(ood_test_loader):\n",
    "        \n",
    "        input_batch = input_batch.to(device)\n",
    "        output_batch = output_batch.to(device)\n",
    "        output_pred_batch = model(input_batch)\n",
    "        \n",
    "        if which_example == \"airfoil\": #Mask the airfoil shape\n",
    "            output_pred_batch[input_batch==1] = 1\n",
    "            output_batch[input_batch==1] = 1\n",
    "        \n",
    "        loss_f = torch.mean(abs(output_pred_batch - output_batch), axis = [1,2,3]) / torch.mean(abs(output_batch), axis = [1,2,3]) * 100\n",
    "        ood_test_relative_l2.append(loss_f.detach().cpu().numpy())\n",
    "    ood_test_relative_l2 = np.concatenate(ood_test_relative_l2, 0)\n",
    "\n",
    "print(np.median(final_test_relative_l2).item())\n",
    "print(np.median(ood_test_relative_l2).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
